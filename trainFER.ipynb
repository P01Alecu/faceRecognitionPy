{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 14:06:10.059183: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-10 14:06:10.811863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-10 14:06:12.344606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.394886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.395081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.983510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.983918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.984159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.984308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3323 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-06-10 14:06:12.985238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.985502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:12.985630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.layers import Resizing\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def fix_gpu():\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "\n",
    "def prepare_data():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def plot_model_history(history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axs[0].plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'])\n",
    "    axs[0].plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "    axs[1].plot(range(1, len(history.history['loss']) + 1), history.history['loss'])\n",
    "    axs[1].plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "\n",
    "    fig.savefig('train.png')\n",
    "    plt.show()\n",
    "\n",
    "#def build_model_from_url(url):\n",
    "#        \"\"\"\n",
    "#        Takkes a TensorFlow Hub URL and creates a Keras Sequential model with it. \n",
    "#\n",
    "#\n",
    "#        \"\"\"\n",
    "#\n",
    "#        # Download the pretrained model and save it as keras layer\n",
    "#        feature_extractor_layer = hub.KerasLayer(url,\n",
    "#                                                trainable=False,\n",
    "#                                                name=\"feature_extraction_layer\",\n",
    "#                                                input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "#\n",
    "#        # Create our own model\n",
    "#        model = tf.keras.Sequential()\n",
    "#        model.add(Resizing(48, 48))\n",
    "#        model.add(tf.keras.layers.Lambda(lambda x: tf.repeat(x, 3, axis=-1), input_shape=(48, 48, 1)))\n",
    "#        model.add(feature_extractor_layer)\n",
    "#        model.add(Dense(7, activation=\"softmax\", name=\"output_layer\"))\n",
    "#        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#        return model\n",
    "\n",
    "train_data_dir = 'data/fer/train/'\n",
    "validation_data_dir = 'data/fer/test/'\n",
    "\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "batch_size = 32\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "fix_gpu()\n",
    "train_generator, validation_generator = prepare_data()\n",
    "input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "#url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
    "#if(len(url) > 3):\n",
    "#    model = build_model_from_url()\n",
    "#else:\n",
    "#    model = build_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.1))\\n\\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.1))\\n\\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.1))\\n\\nmodel.add(Flatten())\\nmodel.add(Dense(512, activation='relu'))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(7, activation='softmax'))\\n\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\nprint(model.summary())\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model in GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Flatten())\\nmodel.add(Dense(128, activation='relu'))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.5))\\n\\nmodel.add(Dense(7, activation='softmax'))\\n\\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five layer model from GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 14:06:14.271846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:14.272041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:14.272163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:14.272368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:14.272491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-10 14:06:14.272579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3323 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(4, 4), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "# Add the third convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "# Flatten the tensor output from the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(7, activation='softmax')) # assuming 10 classes for CIFAR-10 dataset\n",
    "\n",
    "# Configure the learning process\n",
    "optimizer = SGD(learning_rate=0.1, momentum=0.9, decay=0.0001)\n",
    "model.compile(loss=CategoricalCrossentropy(), optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 14:06:14.520781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-10 14:06:15.580591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-10 14:06:16.319946: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: logits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,7]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_30026/4026209910.py\", line 3, in <module>\n      history = model.fit(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/backend.py\", line 5565, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,7]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1485]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      4\u001b[0m     train_generator,\n\u001b[1;32m      5\u001b[0m     \u001b[39m#steps_per_epoch=num_train_imgs // batch_size,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator\n\u001b[1;32m      8\u001b[0m     \u001b[39m#validation_steps=num_test_imgs // batch_size,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39m#callbacks=[early_stopping]\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel_test.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m plot_model_history(history)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_30026/4026209910.py\", line 3, in <module>\n      history = model.fit(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/gabriel/miniconda3/envs/tf/lib/python3.8/site-packages/keras/backend.py\", line 5565, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,7]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1485]"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max', verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    #epochs=100,\n",
    "    validation_data=validation_generator\n",
    "    #callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "model.save('model_test.h5')\n",
    "plot_model_history(history)\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
